# ğŸ“ RAG Admission Officer Chatbot

An intelligent chatbot system that answers student questions about university admissions, fees, academics, and more using **Retrieval-Augmented Generation (RAG)** powered by **Ollama**, **Chroma**, and conversational memory.

---

## âœ¨ Features

- **ğŸ¤– AI-Powered Responses** - Uses Ollama's Llama 3.2 model to generate contextual answers
- **ğŸ¯ Category-Based Filtering** - Routes questions to relevant Q&A categories (Admissions, Fees, Academics, etc.)
- **ğŸ’¾ Semantic Search** - Finds the most relevant answers using vector embeddings
- **ğŸ§  Conversation Memory** - Remembers the last 10 interactions for contextual follow-ups
- **ğŸ“š Easy Q&A Management** - Store all questions and answers in a simple JSON file
- **âš¡ Fast Retrieval** - Uses Chroma vector database with HNSW indexing for quick searches
- **ğŸ”’ Clean Output** - Automatically removes internal metadata from responses

---

## ğŸ“‹ Prerequisites

### Required
- **Python 3.8+**
- **Ollama** (local LLM server) - [Download](https://ollama.ai)
- **Ollama Models**:
  - `all-minilm` (embedding model)
  - `llama3.2` (chat model)

### Installation
```bash
# Install Ollama and pull required models
ollama pull all-minilm
ollama pull llama3.2

# Start Ollama server (runs in background on port 11434)
ollama serve
```

---

## ğŸš€ Quick Start

### 1. Clone & Setup
```bash
# Create Python virtual environment
python -m venv .venv

# Activate venv
# Windows:
.\.venv\Scripts\Activate.ps1
# Mac/Linux:
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment
```bash
# Copy and edit configuration (optional)
copy .env.example .env
# Or use defaults (Ollama on localhost:11434)
```

### 3. Ingest Q&A Data
```bash
python -m src.ingest
```
This reads `data.json` and creates embeddings in `chroma_db/`

### 4. Run the Chatbot
```bash
python -m src.query
```

Then type your questions:
```
Question> What programs do you offer?
ğŸ·ï¸ Detected category: Admissions
--- ANSWER ---
[Bot responds with relevant information]
[Memory: 1/10 interactions stored]

Question> How much is the tuition?
ğŸ·ï¸ Detected category: Fees
--- ANSWER ---
[Bot responds with fee information, remembering previous context]
[Memory: 2/10 interactions stored]
```

**Commands:**
- Type your question â†’ Get an answer
- Type `clear` â†’ Reset conversation memory
- Type `exit` or `quit` â†’ Close the chatbot

---

## ğŸ“ Project Structure

```
RAG - Admission Officer/
â”œâ”€â”€ src/                          # Core application code
â”‚   â”œâ”€â”€ ingest.py                # Reads data.json, creates embeddings
â”‚   â”œâ”€â”€ query.py                 # Interactive chatbot interface
â”‚   â”œâ”€â”€ ollama_client.py         # Ollama API wrapper
â”‚   â””â”€â”€ utils.py                 # Helper functions & conversation memory
â”œâ”€â”€ data.json                    # â­ Q&A dataset (questions, answers, categories)
â”œâ”€â”€ Categories.txt               # Category definitions & keywords
â”œâ”€â”€ chroma_db/                   # Vector database (auto-created)
â”œâ”€â”€ rag_results_llama/           # Query logs (auto-created)
â”œâ”€â”€ .env.example                 # Configuration template
â”œâ”€â”€ requirements.txt             # Python dependencies
â””â”€â”€ README.md                    # This file
```

---

## ğŸ”§ Configuration

Edit `.env` to customize (or use defaults):

```env
# Ollama Server
OLLAMA_HOST=127.0.0.1
OLLAMA_PORT=11434

# Model Names
EMBED_MODEL=all-minilm           # For text â†’ vector embeddings
LLM_MODEL=llama3.2               # For generating answers

# Chroma Database Path
CHROMA_PERSIST_DIR=./chroma_db
```

---

## ğŸ“Š Q&A Data Format

`data.json` should be a JSON array with this structure:

```json
[
  {
    "id": 1,
    "category": "Admissions",
    "question": "What are the admission requirements?",
    "answer": "You need a high school diploma, a minimum GPA of 3.0..."
  },
  {
    "id": 2,
    "category": "Fees",
    "question": "What is the tuition cost?",
    "answer": "Annual tuition is $15,000..."
  },
  {
    "id": 3,
    "category": "Emails",
    "question": "What is the admissions email?",
    "answer": "You can reach us at admissions@university.edu"
  }
]
```

### Supported Categories
- **Admissions** - Application requirements, deadlines, acceptance
- **Fees** - Tuition, costs, payment plans
- **Academics** - GPA, grades, course information
- **Academic Advising** - Advisors, course selection, major planning
- **IT & Systems** - Moodle, portals, technical support
- **Emails** - Contact information, email addresses
- **General** - Any other questions

---

## ğŸ”„ How It Works

### Ingestion Pipeline
```
data.json 
  â†“
[Extract Q&A pairs with categories]
  â†“
[Embed text using Ollama's all-minilm]
  â†“
[Store vectors + metadata in Chroma]
  â†“
chroma_db/ (ready for queries)
```

### Query Pipeline
```
User Question
  â†“
[Detect category from keywords]
  â†“
[Embed question using all-minilm]
  â†“
[Retrieve top 4 similar Q&A from Chroma]
  â†“ (apply category filter if detected)
[Format context + conversation history]
  â†“
[Send to Llama 3.2 with system prompt]
  â†“
[Clean output (remove metadata)]
  â†“
[Save to logs, update memory]
  â†“
Display Answer to User
```
---

**Last Updated:** December 2025  
**Version:** 1.0

